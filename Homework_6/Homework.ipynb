{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 6\n",
    "\n",
    "In this homework you are going to use the Harris corner detector to detect the corners of a document. Document detection is a crucial task for many applications, e.g., text recognition, automatic passport reading (at airport gates), etc.\n",
    "\n",
    "You will also have to design your own feature descriptor in order to localize and distinguish among the 4 document corners.\n",
    "\n",
    "At the end of this notebook, there are a couple of questions for you to answer.\n",
    "\n",
    "So let's begin, shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the image we will be working on in this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read the image\n",
    "img = cv2.imread('data/document.jpg')\n",
    "# Convert it to gray scale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)/255\n",
    "rows, cols = gray.shape\n",
    "\n",
    "# Let's plot the images (colour and gray scale)\n",
    "plt.subplot(121), plt.imshow(img)\n",
    "plt.subplot(122), plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harris Corner Detector\n",
    "Let us now compute Harris corners. Remember that the Harris detector computes the \"cornerness\" score for each image pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Harris corners (use the available OpenCV functions)\n",
    "# Suggested parameters:\n",
    "#            block size of 2 pixels\n",
    "#            gradient kernel size of 3 pixels\n",
    "#            k parameter equal to 0.04\n",
    "cornerness = cv2.cornerHarris(gray, blockSize=2, ksize=3, k=0.04)\n",
    "# We are not interested in edges, so put to zero all negative cornerness values\n",
    "cornerness[cornerness < 0] = 0\n",
    "\n",
    "# Since cornerness has a huge dynamic range, let's take the logarithm for better visualization and manipulation\n",
    "cornerness = np.log(cornerness + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now plot the image and the corresponding Harris corners (in log scale)\n",
    "plt.subplot(121), plt.imshow(img)\n",
    "plt.subplot(122), plt.imshow(cornerness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you can see that the Harris detector has detected a lot of features. Not only the four document corners, but also the corners corresponding to (black) letters printed on (white) paper. How can we filter out everything but the 4 document corners?\n",
    "\n",
    "For that purpose, let's design a custom feature descriptor suitable to detect the document corners. In order to do so, let's have a look at the top left corner.\n",
    "\n",
    "![Top-left corner](data/document_descriptor_example.jpg \"Top-left corner\")\n",
    "\n",
    "A good descriptor of that corner, given a certain neghbouring region, would be to assess that the bottom-right quadrant is (much) brighter than the other three quadrants (i.e. top-left, top-right, bottom-left). Let's then implement it :-) I'll do the implementation for the top-left corner, you shall do the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Detection thresholds\n",
    "th_top_left, th_top_right = -1e6, -1e6\n",
    "th_bottom_left, th_bottom_right = -1e6, -1e6\n",
    "\n",
    "# Corner coordinates\n",
    "opt_top_left, opt_top_right = None, None\n",
    "opt_bottom_left, opt_bottom_right = None, None\n",
    "\n",
    "# Size of each quadrant (in pixels)\n",
    "quad_size = 7\n",
    "\n",
    "# Let's now scan the Harris detection results\n",
    "for r in range(quad_size, rows-quad_size):\n",
    "    for c in range(quad_size, cols-quad_size):\n",
    "        # Edges with too small cornerness score are discarded, -7 seems like a good value\n",
    "        if cornerness[r, c] < -7:\n",
    "            continue\n",
    "        \n",
    "        # Extract block consisting of 4 quadrants\n",
    "        block = 255*gray[r-quad_size:r+quad_size+1, c-quad_size:c+quad_size+1]\n",
    "        \n",
    "        # Extract the four quandrants\n",
    "        quad_top_left = block[0:quad_size, 0:quad_size]\n",
    "        # quad_top_right = block[0:quad_size, quad_size+1:2*quad_size+1]\n",
    "        # quad_bottom_left = block[quad_size+1:2*quad_size+1, 0:quad_size]\n",
    "        # quad_bottom_right2 = block[quad_size+1:2*quad_size+1, quad_size+1:2*quad_size+1]\n",
    "        quad_top_right = block[0:quad_size, quad_size+1:]\n",
    "        quad_bottom_left = block[quad_size+1:, 0:quad_size]\n",
    "        quad_bottom_right = block[quad_size+1:, quad_size+1:]\n",
    "\n",
    "        # Top-left corner\n",
    "        # For the top-left document corner, the bottom-right quadrant is mostly paper and the rest is\n",
    "        # darker background. Therefore, I suggest the descriptor to be the average difference between\n",
    "        # the paper quandrant and the sum of the 3 remaining bakcground quandrants\n",
    "        descriptor_top_left = np.mean(quad_bottom_right) - np.mean(quad_top_left) - np.mean(quad_top_right) - np.mean(quad_bottom_left)\n",
    "        # Let's detect the best descriptor\n",
    "        if descriptor_top_left > th_top_left:\n",
    "            # We update the threshold\n",
    "            th_top_left = descriptor_top_left\n",
    "            # And we update the optimal location\n",
    "            opt_top_left = (c, r)\n",
    "            \n",
    "        # Top-right corner\n",
    "        descriptor_top_right = np.mean(quad_bottom_left) - np.mean(quad_bottom_right) - np.mean(quad_top_left) - np.mean(quad_top_right)\n",
    "        # Let's detect the best descriptor\n",
    "        if descriptor_top_right > th_top_right:\n",
    "            # We update the threshold\n",
    "            th_top_right = descriptor_top_right\n",
    "            # And we update the optimal location\n",
    "            opt_top_right = (c, r)\n",
    "            \n",
    "        # Bottom-left corner\n",
    "        descriptor_bottom_left = np.mean(quad_top_right) - np.mean(quad_bottom_left) - np.mean(quad_bottom_right) - np.mean(quad_top_left)\n",
    "        # Let's detect the best descriptor\n",
    "        if descriptor_bottom_left > th_bottom_left:\n",
    "            # We update the threshold\n",
    "            th_bottom_left = descriptor_bottom_left\n",
    "            # And we update the optimal location\n",
    "            opt_bottom_left = (c, r)\n",
    "            \n",
    "        # Bottom-right corner\n",
    "        descriptor_bottom_right = np.mean(quad_top_left) - np.mean(quad_top_right) - np.mean(quad_bottom_left) - np.mean(quad_bottom_right)\n",
    "        # Let's detect the best descriptor\n",
    "        if descriptor_bottom_right > th_bottom_right:\n",
    "            # We update the threshold\n",
    "            th_bottom_right = descriptor_bottom_right\n",
    "            # And we update the optimal location\n",
    "            opt_bottom_right = (c, r)\n",
    "\n",
    "# Let's draw circles at the detected corners\n",
    "out = cv2.circle(img, opt_top_left, 3, (255,0,0), -1)\n",
    "out = cv2.circle(img, opt_top_right, 3, (255,0,0), -1)\n",
    "out = cv2.circle(img, opt_bottom_left, 3, (255,0,0), -1)\n",
    "out = cv2.circle(img, opt_bottom_right, 3, (255,0,0), -1)\n",
    "\n",
    "# And finally we plot the images (with the detected document corners)\n",
    "plt.subplot(121), plt.imshow(out)\n",
    "plt.subplot(122), plt.imshow(cornerness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* Does it matter whether the picture has been taken by a 1Mpx camera or a 12Mpx camera? How?\n",
    "\n",
    "    The more megapixels in the camera that took the photo, the higher its resolution. Since the Harris algorithm is not scaling invariant, we may not find the keypoints we are interested in (corners).\n",
    "\n",
    "* If we increased the resolution of the camera, what would you change in the current algorithm?\n",
    "\n",
    "    Variant 1. Resize image to smoller resolution\n",
    "    \n",
    "    Variant 2. Increase cornerHarris params blockSize, ksize and increase quad_size\n",
    "\n",
    "Remember, I am **not** looking for a particular answer. I want to see how you think, so be creative ;-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hw4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3342132b8aa46483c107ea6e46b3799fe8e5161f8b4b9b5459ca3d28e4574eb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
