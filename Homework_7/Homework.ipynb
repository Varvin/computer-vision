{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 7\n",
    "\n",
    "In this homework you are going to rectify a document image that suffers from severe distortion. You will be using the same image and the same detected corners from the previous lesson (lesson 6).\n",
    "\n",
    "Remember, OpenCV documentation is your friend ;-)\n",
    "\n",
    "At the end of this notebook, there are a couple of questions for you to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the image we will be working on in this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('../Homework_6/data/document.jpg')\n",
    "img = cv2.imread('../Homework_6/data/test2.jpeg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)/255\n",
    "rows, cols = gray.shape\n",
    "size = (cols, rows)\n",
    "\n",
    "# Let's plot the image\n",
    "plt.subplot(121), plt.imshow(img)\n",
    "plt.subplot(122), plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous homework you should have detected the four document corners and you will need to use them here. But don't worry if the previous homework did not work out for you, I am going to provide you with the corners coordinates here :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points_img_document():\n",
    "    return [76, 115], [219, 111], [43, 330], [256, 329]\n",
    "\n",
    "def get_points_img_test2():\n",
    "    return [426,113], [1010,187], [219,839], [902,1014]\n",
    "\n",
    "# top_left, top_right, bottom_left, bottom_right = get_points_img_document()\n",
    "\n",
    "top_left, top_right, bottom_left, bottom_right = get_points_img_test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the points\n",
    "out = np.copy(img)\n",
    "out = cv2.circle(out, tuple(top_left), 3, (255,0,0), -1)\n",
    "out = cv2.circle(out, tuple(top_right), 3, (255,0,0), -1)\n",
    "out = cv2.circle(out, tuple(bottom_left), 3, (255,0,0), -1)\n",
    "out = cv2.circle(out, tuple(bottom_right), 3, (255,0,0), -1)\n",
    "\n",
    "plt.subplot(121), plt.imshow(img)\n",
    "plt.subplot(122), plt.imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Rectification\n",
    "\n",
    "Let's now try to rectify the document. The goal is to bring the four document corners to the image corners. For instance, we want the top-left document corner to become (0, 0), i.e., the top-left corner of the image itself. In that way, we will fill the complete image with document information and we will throw away parts of the images that correspond to background (which are of no use to us)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the matrix of source points corresponding to the 4 document corners.\n",
    "# The matrix shall have shape (4, 2), i.e., 4 corners x 2 coordinates\n",
    "# Note: You will need to explicitly use float32 data type\n",
    "src = np.array([top_left,top_right,bottom_left,bottom_right], dtype=np.float32)\n",
    "\n",
    "# Define the matrix of target (destination) points corresponding to the 4 image corners.\n",
    "# The matrix shall have shape (4, 2), i.e., 4 corners x 2 coordinates\n",
    "# Note: You will need to explicitly use float32 data type\n",
    "# Note2: The order of points in src and dst must be the same\n",
    "\n",
    "dst = np.array([[0,0],[cols,0],[0,rows],[cols,rows]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first start with the affine transform for document rectification. The affine transform can be analytically calculated using 3 point pairs. Therefore, let's select the **first 3 points** and calculate the correspnding transfrom. We will then use the transform to rectify the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the affine transform matrix (you'll have to use getAffineTransform function from OpenCV here)\n",
    "# Use the first 3 points from your src and dst matrix\n",
    "M = cv2.getAffineTransform(src[:3], dst[:3])\n",
    "\n",
    "# Build the rectified image using the computed matrix (you'll have to use warpAffine function from OpenCV here)\n",
    "rectified = cv2.warpAffine(img, M, size)\n",
    "\n",
    "# Let's plot the results\n",
    "plt.subplot(121), plt.imshow(img)\n",
    "plt.subplot(122), plt.imshow(rectified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this is not bad by certainly not what we were aiming for. Let's try the **last 3** points instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the affine transform matrix (use getAffineTransform)\n",
    "# Use the last 3 points from your src and dst matrix\n",
    "M = cv2.getAffineTransform(src[1:], dst[1:])\n",
    "\n",
    "# Build the rectified image using the computed matrix (use warpAffine)\n",
    "rectified = cv2.warpAffine(img, M, size)\n",
    "\n",
    "# Let's plot the results\n",
    "plt.subplot(121), plt.imshow(img)\n",
    "plt.subplot(122), plt.imshow(rectified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result looks different but not better. This approach doesn't seem to be helping then. Let's use **all 4 points** and let OpenCV **estimate** (remember that 4 points are too many for an analytical solution) the best fitting affine transform for us. It'll internally apply optimization approaches as well as RANSAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the optimal affine transform matrix (you'll have to use estimateAffine2D function from OpenCV here)\n",
    "# estimateAffine2D it returns the best fitting affine matrix as well as the vector of inliers (1 -> inlier,\n",
    "# 0 -> outlier).\n",
    "M, inliers = cv2.estimateAffine2D(src, dst, cv2.RANSAC)\n",
    "\n",
    "print(M)\n",
    "print(inliers)\n",
    "\n",
    "# Build the rectified image using the computed matrix (use warpAffine)\n",
    "rectified = cv2.warpAffine(img, M, size)\n",
    "\n",
    "# Let's plot the results\n",
    "plt.subplot(121), plt.imshow(img)\n",
    "plt.subplot(122), plt.imshow(rectified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much of an improvement either. Let's try homography instead of affine transform. Remember that for computing the homography analytically we need to use 4 pairs of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the homography matrix (you'll have to use getPerspectiveTransform function from OpenCV here)\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "# Build the rectified image using the computed matrix (you'll have to use warpPerspective function from OpenCV)\n",
    "rectified = cv2.warpPerspective(img, M, size)\n",
    "\n",
    "# Let's plot the results\n",
    "plt.subplot(121), plt.imshow(img)\n",
    "plt.subplot(122), plt.imshow(rectified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* The affine transform does not seem to be working well in this case. Why?\n",
    "\n",
    "    Affine transformation preserves parallelism (relationships of key points), the task used an image and perspective distortion, which required obtaining parallel ones where they are not\n",
    "\n",
    "* What can you tell me about the values you have obtained for the inliers vector? What does it mean?\n",
    "\n",
    "    I received inliers = ```[[1] [1] [0] [1]]```. The result obtained tells us which elements from the src and dst matrix were chosen as optimal for the affine transformation.\n",
    "    Ð•his means that we can call the function getAffineTransform and pass coordinates of points ```top_left, top_right and bottom_left``` to it and get the same matrix for affine transformation.\n",
    "\n",
    "* How does the result from homography look? Does it work well enough? \n",
    "\n",
    "    The homography result looks like the document was photographed from above at an angle of 90 to it. The result looks much better than applying the affine transformation, but still has little distortion in the result.\n",
    "\n",
    "Remember, I am **not** looking for a particular answer. I want to see how you think, so be creative ;-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hw4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3342132b8aa46483c107ea6e46b3799fe8e5161f8b4b9b5459ca3d28e4574eb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
