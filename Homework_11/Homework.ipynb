{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 11\n",
    "\n",
    "In this homework you are going to improve the DNN for house price estimation we built during the lesson. The objective is to beat the performance (i.e. to get a closer estimation) of the last network we built in the lecture.\n",
    "\n",
    "The structure of this homework is as follows:\n",
    " * First, we are going to build the reference network (exactly the same network we implemented in the lecture).\n",
    " * You are going to run it a write down the price estimation error (Validation MAE).\n",
    " * Then you are going to make some modifications in order to make the network perform better.\n",
    " \n",
    "In the section **Tasks** you will find what modification you'll need to implement as well as some hints.\n",
    " \n",
    "At the end, as usual, there are some question waiting for you to answer :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "from tensorflow.keras import Model, metrics\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "\n",
    "# Set the seeds\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "seed_value = 1234578790\n",
    "seed(seed_value)\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Let's load the data and prepare the training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/train.csv')\n",
    "\n",
    "features = ['SalePrice','OverallQual', 'GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt', 'LotArea' , 'LotFrontage','OverallQual','OverallCond','YearBuilt','YearRemodAdd', 'GrLivArea', 'GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch']\n",
    "data = dataset[features]\n",
    "\n",
    "# Filling nan with the mean of the column:\n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "# Extract input values and normalize\n",
    "x = data[features[1:]]\n",
    "scale = StandardScaler()\n",
    "x = scale.fit_transform(x)\n",
    "\n",
    "# Extract output values (prices) and normalize\n",
    "y = data[features[0]].values\n",
    "y = y/100000\n",
    "\n",
    "# Split into 75% for train and 25% for test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the same plotting helper we used in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    h = history.history\n",
    "    epochs = range(len(h['loss']))\n",
    "\n",
    "    plt.subplot(121), plt.plot(epochs, h['loss'], '.-', epochs, h['val_loss'], '.-')\n",
    "    plt.grid(True), plt.xlabel('epochs'), plt.ylabel('loss')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.subplot(122), plt.plot(epochs, np.array(h['mean_absolute_error'])*1e5, '.-',\n",
    "                               epochs, np.array(h['val_mean_absolute_error'])*1e5, '.-')\n",
    "    plt.grid(True), plt.xlabel('epochs'), plt.ylabel('MAE')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "        \n",
    "    print('Train MAE     ', h['mean_absolute_error'][-1]*1e5)\n",
    "    print('Validation MAE', h['val_mean_absolute_error'][-1]*1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=x.shape[1])\n",
    "outputs = Dense(128, activation='relu')(inputs)\n",
    "# outputs = Dense(5, activation='relu')(outputs)\n",
    "outputs = Dense(1, activation='linear')(outputs)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer ='adam', loss ='mean_squared_error', metrics =[metrics.mae])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=150, batch_size=32, verbose=0)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "Improve the network so you obtain a better estimation error than the reference. You can try the following:\n",
    "* Add a new feature to your inputs. For instance, `LotArea` (lot size in square feet) seems like a good candidate :-)\n",
    "* Try increasing the number of neurons in the first layer. Currently, we have 5 neurons there, what happens if we increase it to 10?\n",
    "    Train MAE decreased by almost 1000, but Validation MAE increased slightly by 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* What is the new price estimation error after your modifrications? Is it better than before?\n",
    "\n",
    "    Start valuet was:\n",
    "\n",
    "        Train MAE 23658.843338489532\n",
    "        Validation MAE 25390.008091926575\n",
    "    \n",
    "    After adding more input params and increasing layer and neurons count:\n",
    "\n",
    "        Train MAE 16309.159994125366\n",
    "        Validation MAE 21023.87547492981\n",
    "    \n",
    "    The error in price predictions has decreased.\n",
    "\n",
    "* Does adding more features help?\n",
    "\n",
    "    By adding more features, it is possible to reduce the error in the house estimation error (on the same network architecture)\n",
    "\n",
    "* Does adding more neurons help?\n",
    "\n",
    "    By adding more neurons, it is possible to reduce the error in the house estimation error. But if the number of neurons increases, the difference between Train MAE and Validation MAE grows. With an increase in the number of neurons, Train MAE decreases, but this increase does not always significantly reduce Validation MAE\n",
    "\n",
    "* What would you do to improve the network even further?\n",
    "\n",
    "    I would increase the number of features and possibly pick up a different network architecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-mac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4e4f01325c912b79e0f8552eafc8362cdad02ecd1e6192b8db90dbb446990e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
