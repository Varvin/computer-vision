{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 5\n",
    "\n",
    "In this homework you are going to implement the **Floyd-Steinberg dithering** algorithm. Dithering, in general, means that we are adding noise to the signal (in our case digital image) in order to perceive it better. In other words, by adding the noise the objective quality will be worse but the subjective quality will be better (i.e. the image will \"look\" better).\n",
    "\n",
    "The details of FS dithering can be found in this [wiki](https://en.wikipedia.org/wiki/Floyd%E2%80%93Steinberg_dithering) page. In order to implement the dithering, we will implement the following steps:\n",
    "* Define colour palette\n",
    "* Quantize the image to obtain the baseline and compute the average quantization error\n",
    "* Implement FS dithering and compute the average quantization error\n",
    "\n",
    "You will also have to answer the question at the end of this notebook.\n",
    "\n",
    "Note: In this homework, you will have the chance to earn some extra points. See the \"Bonus\" section at the end of the notebook. Good luck!\n",
    "\n",
    "As always, you are encouraged to use your own images :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from math import sqrt, log10\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = cv2.imread('data/kodim23.png')\n",
    "# Convert it to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# Plot it\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with gray tones first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black, dark gray, light gray, white\n",
    "colors = np.array([[0, 0, 0],\n",
    "                   [64, 64, 64],\n",
    "                   [192, 192, 192],\n",
    "                   [255, 255, 255]])\n",
    "colors = colors/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the colour palette, let's quantize the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the image to float\n",
    "img_norm = img\n",
    "img = img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(palette, color):\n",
    "    palette = np.array(palette)\n",
    "    color = np.array(color)\n",
    "    distances = np.sqrt(np.sum((palette-color)**2, axis=1))\n",
    "    index_of_smallest = np.where(distances==np.amin(distances))\n",
    "    smallest_distance = palette[index_of_smallest[0]][0]\n",
    "    return smallest_distance \n",
    "\n",
    "def quantimage(image, palette):\n",
    "    # Prepare for quantization\n",
    "    rows, cols, channels = image.shape\n",
    "    quantized = np.zeros_like(image)\n",
    "\n",
    "    # Apply quantization\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            # Extract the original pixel value\n",
    "            pixel = image[r, c, :]\n",
    "            # Find the closest colour from the palette (using absolute value/Euclidean distance)\n",
    "            # Note: You may need more than one line of code here\n",
    "            new_pixel = closest(palette, pixel)\n",
    "\n",
    "            # Apply quantization\n",
    "            quantized[r, c, :] = new_pixel\n",
    "    return quantized\n",
    "\n",
    "quantized_custom_4_colors = quantimage(img, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    \n",
    "# Show quantized image (don't forget to cast back to uint8)\n",
    "plt.imshow(normalize(quantized_custom_4_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(original, compressed):\n",
    "    return np.mean((original - compressed) ** 2)\n",
    "\n",
    "def psnr(original, compressed):\n",
    "    mse_val = mse(original, compressed)\n",
    "    if(mse_val == 0):  # MSE is zero means no noise is present in the signal .\n",
    "                  # Therefore PSNR have no importance.\n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse_val))\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average quantization error\n",
    "quantized_image_4_mse = mse(img_norm, normalize(quantized_custom_4_colors))\n",
    "quantized_image_4_psnr = psnr(img_norm, normalize(quantized_custom_4_colors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Floyd-Steinberg Dithering\n",
    "We are now going to implement the FS dithering and compare it to the optimally quantized image we have calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def floyd_steinberg_dithering(image, palette):\n",
    "    rows, cols, channels = image.shape\n",
    "    # Make a temporal copy of the original image, we will need it for error diffusion\n",
    "    img_tmp = np.copy(image)\n",
    "    dithering = np.zeros_like(image)\n",
    "\n",
    "    for r in range(1, rows-1):\n",
    "        for c in range(1, cols-1):\n",
    "            # Extract the original pixel value\n",
    "            pixel = img_tmp[r, c, :]\n",
    "            # Find the closest colour from the palette (using absolute value/Euclidean distance)\n",
    "            # Note: You may need more than one line of code here\n",
    "            new_pixel = closest(palette, pixel)\n",
    "            \n",
    "            # Compute quantization error\n",
    "            quant_error = pixel - new_pixel\n",
    "            \n",
    "            # Diffuse the quantization error accroding to the FS diffusion matrix\n",
    "            # Note: You may need more than one line of code here\n",
    "            img_tmp[r, c, :] = new_pixel\n",
    "            img_tmp[r + 1, c, :] = img_tmp[r + 1, c, :] + quant_error * 7 / 16\n",
    "            img_tmp[r - 1, c + 1, :] = img_tmp[r - 1, c + 1, :] + quant_error * 3 / 16\n",
    "            img_tmp[r, c + 1, :] = img_tmp[r, c + 1, :] + quant_error * 5 / 16\n",
    "            img_tmp[r + 1, c + 1, :] = img_tmp[r + 1, c + 1, :] + quant_error * 1 / 16\n",
    "            \n",
    "            # Apply dithering\n",
    "            dithering[r, c, :] = new_pixel\n",
    "    return dithering\n",
    "\n",
    "dithering_custom_4_colors = floyd_steinberg_dithering(img, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show quantized image (don't forget to cast back to uint8)\n",
    "plt.subplot(121), plt.imshow(quantized_custom_4_colors), plt.title('Optimally quantized')   # optimally quantized\n",
    "plt.subplot(122), plt.imshow(dithering_custom_4_colors), plt.title('FS dithering')   # dithering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average quantization error for dithered image\n",
    "FS_dithering_4_mse = mse(img_norm, normalize(dithering_custom_4_colors))\n",
    "FS_dithering_4_psnr = psnr(img_norm, normalize(dithering_custom_4_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE for image after quantization: {}\\nMSE for image after fs-dithering: {}\".format(quantized_image_4_mse, FS_dithering_4_mse))\n",
    "print(\"PSNR for image after quantization: {}\\nPSNR for image after fs-dithering: {}\".format(quantized_image_4_psnr, FS_dithering_4_psnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* Which image has higher quantization error? Optimally quantized or dithered?\n",
    "    \n",
    "    Dithered image has higher quantization error then optimally quantized\n",
    "\n",
    "* Which image looks better to you?\n",
    "    \n",
    "    For me dithered image looks better. I can see more details on it.\n",
    "\n",
    "* Can you repeat the same process using only two colours: black and white? Show me :-)\n",
    "    \n",
    "    Results images you can see in README.md in this homework. (Paragraph 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_white_palette = np.array([[0, 0, 0],\n",
    "                                [255, 255, 255]])\n",
    "black_white_palette = black_white_palette/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_b_w_img = quantimage(img, black_white_palette)\n",
    "d_b_w_img = floyd_steinberg_dithering(img, black_white_palette)\n",
    "\n",
    "q_b_w_img_norm = normalize(q_b_w_img)\n",
    "d_b_w_img_norm = normalize(d_b_w_img)\n",
    "\n",
    "quantized_image_2_mse = mse(img_norm, q_b_w_img_norm)\n",
    "quantized_image_2_psnr = psnr(img_norm, q_b_w_img_norm)\n",
    "FS_dithering_2_mse = mse(img_norm, d_b_w_img_norm)\n",
    "FS_dithering_2_psnr = psnr(img_norm, d_b_w_img_norm)\n",
    "\n",
    "print(\"MSE for image after quantization: {}\\nMSE for image after fs-dithering: {}\".format(quantized_image_2_mse, FS_dithering_2_mse))\n",
    "print(\"PSNR for image after quantization: {}\\nPSNR for image after fs-dithering: {}\".format(quantized_image_2_psnr, FS_dithering_2_psnr))\n",
    "\n",
    "plt.subplot(121), plt.imshow(q_b_w_img), plt.title('Optimally quantized')\n",
    "plt.subplot(122), plt.imshow(d_b_w_img), plt.title('FS dithering') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121), plt.imshow(dithering_custom_4_colors[200:300,500:600]), plt.title('Dithering with 4 colors')\n",
    "plt.subplot(122), plt.imshow(d_b_w_img[200:300,500:600]), plt.title('Dithering with 2 colors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Points\n",
    "\n",
    "Repeat the homework using a diffrerent image palette. For instance, you can use an optimal colour\n",
    "palette that we can calculate via k-means algorithm. The following snippet of code will give you the 16\n",
    "optimal colours for your original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from showlist import show_image_list\n",
    "\n",
    "LABALE = \"Collors: {}, MSE: {:.2f}, PSNR: {:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init palletts\n",
    "\n",
    "def get_collors(image, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters).fit(np.reshape(image, (-1, 3)))\n",
    "    return kmeans.cluster_centers_\n",
    "\n",
    "colors_4 = get_collors(img,4)\n",
    "colors_8 = get_collors(img,8)\n",
    "colors_16 = get_collors(img,16)\n",
    "colors_32 = get_collors(img,32)\n",
    "colors_256 = get_collors(img,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantize images and show result\n",
    "q_4 = quantimage(img, colors_4)\n",
    "q_8 = quantimage(img, colors_8)\n",
    "q_16 = quantimage(img, colors_16)\n",
    "q_32 = quantimage(img, colors_32)\n",
    "q_256 = quantimage(img, colors_256)\n",
    "\n",
    "q_images = [img, q_4, q_8, q_16, q_32, q_256]\n",
    "q_lables = ['original', \n",
    "        LABALE.format(4, mse(img_norm, normalize(q_4)), psnr(img_norm, normalize(q_4))),\n",
    "        LABALE.format(8, mse(img_norm, normalize(q_8)), psnr(img_norm, normalize(q_8))),\n",
    "        LABALE.format(16, mse(img_norm, normalize(q_16)), psnr(img_norm, normalize(q_16))),\n",
    "        LABALE.format(32, mse(img_norm, normalize(q_32)), psnr(img_norm, normalize(q_32))),\n",
    "        LABALE.format(256, mse(img_norm, normalize(q_256)), psnr(img_norm, normalize(q_256)))\n",
    "        ]\n",
    "\n",
    "show_image_list(q_images, q_lables, grid=False, num_cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FS dithering images and show result\n",
    "d_4 = floyd_steinberg_dithering(img, colors_4)\n",
    "d_8 = floyd_steinberg_dithering(img, colors_8)\n",
    "d_16 = floyd_steinberg_dithering(img, colors_16)\n",
    "d_32 = floyd_steinberg_dithering(img, colors_32)\n",
    "d_256 = floyd_steinberg_dithering(img, colors_256)\n",
    "\n",
    "d_images = [img, d_4, d_8, d_16, d_32, d_256]\n",
    "d_lables = ['original', \n",
    "        LABALE.format(4, mse(img_norm, normalize(d_4)), psnr(img_norm, normalize(d_4))),\n",
    "        LABALE.format(8, mse(img_norm, normalize(d_8)), psnr(img_norm, normalize(d_8))),\n",
    "        LABALE.format(16, mse(img_norm, normalize(d_16)), psnr(img_norm, normalize(d_16))),\n",
    "        LABALE.format(32, mse(img_norm, normalize(d_32)), psnr(img_norm, normalize(d_32))),\n",
    "        LABALE.format(256, mse(img_norm, normalize(d_256)), psnr(img_norm, normalize(d_256)))\n",
    "        ]\n",
    "\n",
    "show_image_list(d_images, d_lables, grid=False, num_cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply FS dithering the same way you did before.\n",
    "* How does the result look like to you?\n",
    "    \n",
    "    The results looks better than from palette with gray colors. From 16 colors in palette visual difference from original image is not so noticeable.\n",
    "\n",
    "* What happens if we use 32 colours?\n",
    "\n",
    "    MSE gets smaller and PSNR gets bigger. Background look like has some noize.\n",
    "\n",
    "* And what happens if we use 256 colours?\n",
    "\n",
    "    MSE gets smaller and PSNR gets bigger. Image looks like original\n",
    "\n",
    "Result images in README.md file in this homework. (Paragraph 3 and 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hw4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3342132b8aa46483c107ea6e46b3799fe8e5161f8b4b9b5459ca3d28e4574eb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
