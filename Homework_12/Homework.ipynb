{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 12\n",
    "\n",
    "In this homework you are going to inspect the GTSDB (German Traffic Sign Detection Benchmark) dataset. The dataset contains images of various classes of traffic signs used in Germany (and the whole EU). The objective of this homework is to go through the steps described below and to implement the necessary code.\n",
    "\n",
    "At the end, as usual, there will be a couple of questions for you to answer. In addition, the last section of this homework is optional and, if you chose to do it, you'll earn extra point :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0\n",
    "\n",
    "Go to the GTSRB dataset official site ([link](https://benchmark.ini.rub.de/gtsrb_dataset.html)) to learn more about the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Download the dataset ([link](https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign)) and unzip it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "For this homework, you will be working with the training set. Check out the `Train.csv`, open it and see what it contains. Load the dataset and plot random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training labels\n",
    "root = 'data/GTSRB' # Path to the dataset location, e.g., '/data/janko/dataset/GTSRB'\n",
    "data = pd.read_csv(os.path.join(root, 'Train.csv'))\n",
    "\n",
    "# Number of training samples (amount of samples in data)\n",
    "num_samples = len(data)\n",
    "\n",
    "print(num_samples)\n",
    "\n",
    "# Show random data samples\n",
    "for ii in range(15):\n",
    "    # Get random index\n",
    "    idx = np.random.randint(0, num_samples)\n",
    "    # Load image\n",
    "    img = cv2.imread(os.path.join(root, data.iloc[idx]['Path']))\n",
    "    # Convert image to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Show image\n",
    "    plt.subplot(3,5, ii+1), plt.imshow(img), plt.title(data.iloc[idx]['ClassId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Inspect the dataset by computing and plotting the per-class histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract class identifiers\n",
    "# Hint: Check the csv \n",
    "ids = data['ClassId'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the per class histogram. You can use any approach you want (e.g. `numpy`). It's also worth looking at the `Counter` function from the `collections` module ([link](https://docs.python.org/3/library/collections.html#collections.Counter)) ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "hist = Counter(ids)\n",
    "\n",
    "plt.bar(hist.keys(), hist.values()), plt.grid(True)\n",
    "plt.xlabel('Traffic Sign ID'), plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = 0\n",
    "\n",
    "results = []\n",
    "\n",
    "for class_id in hist.keys():\n",
    "    data_by_class = data[data['ClassId'] == class_id]\n",
    "\n",
    "    images = [cv2.cvtColor(cv2.imread(os.path.join(root, img_path)), cv2.COLOR_BGR2GRAY) for img_path in data_by_class['Path']] #I forgot that the size of the image is in the file Train.csv\n",
    "\n",
    "    info_shape = [image.shape for image in images]\n",
    "    # info_shape = [image.shape[1::-1] for image in images]\n",
    "\n",
    "    total_count = len(images)\n",
    "    unic_shape_by_class = np.unique(info_shape, axis=0)\n",
    "    unic_shape_count_by_class = len(unic_shape_by_class)\n",
    "    max_shape_by_class = np.max(info_shape, axis=0)\n",
    "    min_shape_by_class = np.min(info_shape, axis=0)\n",
    "    mean_shape_by_class = np.mean(info_shape, axis=0)\n",
    "    mean_bright = np.mean([np.mean(image) for image in images])\n",
    "\n",
    "    results.append([class_id, total_count, unic_shape_count_by_class, min_shape_by_class, max_shape_by_class, mean_shape_by_class, mean_bright])\n",
    "\n",
    "results = sorted(results, key=lambda a_entry: a_entry[1])\n",
    "\n",
    "results = np.array(results)\n",
    "\n",
    "fig, axs = plt.subplots(2,1)\n",
    "collabel = ('class_id', 'image_count', 'unic_shapes_count', 'min_shape', 'max_shape', 'mean_shape', 'mean_bright')\n",
    "axs[0].axis('tight')\n",
    "axs[0].axis('off')\n",
    "the_table = axs[0].table(cellText = results, colLabels = collabel, loc = 'top')\n",
    "\n",
    "axs[1].bar(results[:,0],results[:,6])\n",
    "axs[1].set_xlabel('mean_bright')\n",
    "axs[1].set_ylabel('value')\n",
    "axs[1].grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 10\n",
    "for ii in range(15):\n",
    "    idx = np.random.randint(0, len(y_train))\n",
    "    plt.subplot(3,5,ii+1), plt.imshow(x_train[idx, ...], cmap='gray'), plt.title(y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = np.arange(0, num_classes + 1)\n",
    "counts, bounds = np.histogram(y_train, bins=centers-0.5)\n",
    "\n",
    "plt.bar(centers[:-1], counts), plt.grid(True)\n",
    "plt.xlabel('Class ID'), plt.ylabel('counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = np.where(y_train == 7)\n",
    "filter = (y_train == 7).flatten()\n",
    "print(filter.shape)\n",
    "x_train_gray = np.array([cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) for image in x_train])\n",
    "\n",
    "b = y_train[filter]\n",
    "a = x_train_gray[filter, ...]\n",
    "print(b)\n",
    "print(len(filter), len(b), len(x_train_gray))\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "print(x_train_gray.shape)\n",
    "print(b.shape)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for class_id in range(num_classes):\n",
    "    \n",
    "    filter = (y_train == class_id).flatten()\n",
    "    y_train_ = y_train[filter]\n",
    "    x_train_ = x_train[filter, ...]\n",
    "\n",
    "    info_shape = [image.shape for image in x_train_]\n",
    "    # info_shape = [image.shape[1::-1] for image in images]\n",
    "\n",
    "    total_count = len(x_train_)\n",
    "    unic_shape_by_class = np.unique(info_shape, axis=0)\n",
    "    unic_shape_count_by_class = len(unic_shape_by_class)\n",
    "    max_shape_by_class = np.max(info_shape, axis=0)\n",
    "    min_shape_by_class = np.min(info_shape, axis=0)\n",
    "    mean_shape_by_class = np.mean(info_shape, axis=0)\n",
    "    print(x_train_.shape)\n",
    "    mean_bright = np.mean([np.mean(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)) for image in x_train_])\n",
    "\n",
    "    results.append([class_id, total_count, unic_shape_count_by_class, min_shape_by_class, max_shape_by_class, mean_shape_by_class, mean_bright])\n",
    "\n",
    "results = sorted(results, key=lambda a_entry: a_entry[1])\n",
    "\n",
    "results = np.array(results)\n",
    "\n",
    "fig, axs = plt.subplots(2,1)\n",
    "collabel = ('class_id', 'image_count', 'unic_shapes_count', 'min_shape', 'max_shape', 'mean_shape', 'mean_bright')\n",
    "axs[0].axis('tight')\n",
    "axs[0].axis('off')\n",
    "the_table = axs[0].table(cellText = results, colLabels = collabel, loc = 'top')\n",
    "\n",
    "axs[1].bar(results[:,0],results[:,6])\n",
    "axs[1].set_xlabel('mean_bright')\n",
    "axs[1].set_ylabel('value')\n",
    "axs[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "Please answer the following questions:\n",
    "* Do you consider the dataset to be balanced? If so, why? If not, why?\n",
    "\n",
    "    No. The number of images per class is not normally distributed. Image sizes vary greatly within and between classes.\n",
    "\n",
    "* Are there any classes that are (significantly) over-represented or under-represeneted?\n",
    "\n",
    "    Yes. \n",
    "\n",
    "        Over-represented classes: 10, 38, 12, 13, 1, 2.\n",
    "\n",
    "        Under-represeneted classes: 0, 19, 27, 37, 32, 41,42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "\n",
    "Perform a further analysis on the dataset and draw some conclusion from it.\n",
    "\n",
    "Hint 1: Unlike MNIST or CIFAR10, this dataset contains images with various spatial resolutions. Is there anything we can tell about the resolution distribution?\n",
    "\n",
    "    In CIFAR10 dataset all images with resolution 32x32.\n",
    "\n",
    "Hint 2: What about the brightness distribution? Are there classes there are significantly more bright than others?\n",
    "\n",
    "    In the CIFAR 10 data set, the brightness distribution is approximately the same level without large drops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-mac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4e4f01325c912b79e0f8552eafc8362cdad02ecd1e6192b8db90dbb446990e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
